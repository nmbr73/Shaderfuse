--[[--/*

  KissTracing.fuse

  Based on https://www.shadertoy.com/view/sttXWX a WebGL shader created by tsaari42.
  Converted to DCTL and embeddet into a Lua Fuse by JiPi (https://www.youtube.com/c/JiPi_YT).
  Place this file in your Fusion's and/or DaVinci Resolve's 'Fuses/' folder to use it.

*/--]]--




-- /*
local ShaderFuse = require("Shaderfuse/ShaderFuse")
ShaderFuse.init()



-- // ------------------------------------------------------------------------
-- // Registry declaration
-- // ------------------------------------------------------------------------

FuRegisterClass(ShaderFuse.FuRegister.Name, CT_SourceTool, {
  ShaderFuse.FuRegister.Attributes,
  REG_NoObjMatCtrls      = true,
  REG_NoMotionBlurCtrls  = true,
  REG_Source_GlobalCtrls = false,
  REG_Source_SizeCtrls   = true,
  REG_Source_AspectCtrls = true,
  REG_Source_DepthCtrls  = true,
  REG_OpNoMask           = true,
  REG_TimeVariant        = true,
  })



-- // ------------------------------------------------------------------------
-- // DCTL kernel parameters
-- // ------------------------------------------------------------------------

-- */
ShaderParameters =
[[

  float  iResolution[2];
  float  iTime;
  float  iMouse[4];

  int    width,height;
  int    compOrder;

]]
-- /*



-- // ------------------------------------------------------------------------
-- DCTL kernel compatibility code
-- // ------------------------------------------------------------------------

-- */
ShaderCompatibilityCode =
[[


#if defined(DEVICE_IS_METAL)
  #define in
  #define out thread
  #define inout thread
#else
  #define in
  #define out
  #define inout
#endif

#undef USE_NATIVE_METAL_IMPL
#undef USE_NATIVE_CUDA_IMPL
#undef USE_NATIVE_OPENCL_IMPL

  // 0 to use the generic implementations; 1 for Metal, OpenCL, Cuda specific code if existing

  #if 1
    #if defined(DEVICE_IS_METAL)
      #define USE_NATIVE_METAL_IMPL   1
    #elif defined(DEVICE_IS_CUDA)
      #define USE_NATIVE_CUDA_IMPL    1
    #elif defined(DEVICE_IS_OPENCL)
      #define USE_NATIVE_OPENCL_IMPL  1
    #endif
  #endif

  #if defined(USE_NATIVE_METAL_IMPL)

    #define swi2(A,a,b)     (A).a##b
    #define swi3(A,a,b,c)   (A).a##b##c

  #else

    #define swi2(A,a,b)     to_float2((A).a,(A).b)
    #define swi3(A,a,b,c)   to_float3((A).a,(A).b,(A).c)

  #endif

// ----------------------------------------------------------------------------------------------------------
// mat4 implementation
// ----------------------------------------------------------------------------------------------------------

#if defined(USE_NATIVE_METAL_IMPL)

  typedef float4x4 mat4;

  __DEVICE__ inline mat4 to_mat4_f4( float4 a, float4 b, float4 c, float4 d ) { return mat4(a,b,c,d); }
  __DEVICE__ inline float4 mul_mat4_f4( mat4 B, float4 A) { return (B*A); }
  __DEVICE__ inline mat4 mul_mat4_mat4( mat4 A, mat4 B) { return (A*B); }

#else

  typedef struct { float4 r0; float4 r1; float4 r2; float4 r3; } mat4;


__DEVICE__ inline mat4 to_mat4( float  a, float  b, float c,   float d, float e, float f,   float g, float h, float i, float j, float k, float l, float m, float n, float o, float p)
{
  mat4 t;
  t.r0.x = a; t.r0.y = b; t.r0.z = c; t.r0.w = d;
  t.r1.x = e; t.r1.y = f; t.r1.z = g; t.r0.w = h;
  t.r2.x = i; t.r2.y = j; t.r2.z = k; t.r0.w = l;
  t.r3.x = m; t.r3.y = n; t.r3.z = o; t.r0.w = p;
  return t;
}


__DEVICE__ inline mat4 to_mat4_f4( float4 A, float4 B, float4 C, float4 D)
  {
    mat4 _ret;
    _ret.r0 = A;
    _ret.r1 = B;
    _ret.r2 = C;
    _ret.r3 = D;
    return _ret;
  }

__DEVICE__ inline float4 mul_mat4_f4( mat4 B, float4 A)
  {
    float4 C;
    C.x = A.x * B.r0.x + A.y * B.r1.x + A.z * B.r2.x + A.w * B.r3.x;
    C.y = A.x * B.r0.y + A.y * B.r1.y + A.z * B.r2.y + A.w * B.r3.y;
    C.z = A.x * B.r0.z + A.y * B.r1.z + A.z * B.r2.z + A.w * B.r3.z;
    C.w = A.x * B.r0.w + A.y * B.r1.w + A.z * B.r2.w + A.w * B.r3.w;
    return C;
}

__DEVICE__ inline mat4 mul_mat4_mat4( mat4 B, mat4 A)
{

  float r[4][4];
  float a[4][4] = {{A.r0.x, A.r0.y, A.r0.z, A.r0.w},
                   {A.r1.x, A.r1.y, A.r1.z, A.r1.w},
                   {A.r2.x, A.r2.y, A.r2.z, A.r2.w},
                   {A.r3.x, A.r3.y, A.r3.z, A.r3.w}};
  float b[4][4] = {{B.r0.x, B.r0.y, B.r0.z, B.r0.w},
                   {B.r1.x, B.r1.y, B.r1.z, B.r1.w},
                   {B.r2.x, B.r2.y, B.r2.z, B.r2.w},
                   {B.r3.x, B.r3.y, B.r3.z, B.r3.w}};

  for( int i = 0; i < 4; ++i)
  {
   for( int j = 0; j < 4; ++j)
   {
     r[i][j] = 0.0f;
     for( int k = 0; k < 4; ++k)
     {
     r[i][j] = r[i][j] + a[i][k] * b[k][j];
     }
   }
  }
  mat4 R = to_mat4(r[0][0], r[0][1], r[0][2], r[0][3],
                   r[1][0], r[1][1], r[1][2], r[1][3],
                   r[2][0], r[2][1], r[2][2], r[2][3],
                   r[3][0], r[3][1], r[3][2], r[3][3]);
  return R;
}
#endif // end of mat4 implementation

#if defined(USE_NATIVE_METAL_IMPL)

 #define mod_f(a,b)  fmod((a),(b))

#else

  #if defined(USE_NATIVE_OPENCL_IMPL)

    #define reflect(I,N) (I-2.0f*dot(N,I)*N)

    #define fract(a) ((a)-_floor(a))  // oder Pointer bauen: gentype fract(gentype x, gentype *itpr)

 #define mod_f(a,b) _fmod(a,b)

 #else // Generic

 #if defined(DEVICE_IS_OPENCL)
   __DEVICE__ float3 reflect(float3 I, float3 N) {return I - 2.0f * dot(N, I) * N;}
 #endif

    #define fract(a) ((a)-_floor(a))

 #define mod_f(a,b) ((a)-(b)*_floor((a)/(b)))

  #endif

#endif

__DEVICE__ float4 decube_f3(__TEXTURE2D__ t, float3 xyz)
{
  float ax=_fabs(xyz.x);
  float ay=_fabs(xyz.y);
  float az=_fabs(xyz.z);

  if (xyz.x>0.0f && ax>=ay && ax>=az) // +X, Face 0, right
    return _tex2DVecN(t,(-xyz.z/ax+1.0f)/8.0f + 0.5f,(xyz.y/ax+1.0f)/6.0f + (1.0f/3.0f),15);

  if (xyz.y>0.0f && ay>=ax && ay>=az) // +Y, Face 2, top
    return _tex2DVecN(t,(xyz.x/ay+1.0f)/8.0f + 0.25f,(-xyz.z/ay+1.0f)/6.0f + (2.0f/3.0f),15);

  if (xyz.z>0.0f && az>=ax && az>=ay) // +Z, Face 4, front
    return _tex2DVecN(t,(xyz.x/az+1.0f)/8.0f + 0.25f,(xyz.y/az+1.0f)/6.0f + (1.0f/3.0f),15);

  if (xyz.x<0.0f && ax>=ay && ax>=az) // -X, Face 1, left
    return _tex2DVecN(t,(xyz.z/ax+1.0f)/8.0f,(xyz.y/ax+1.0f)/6.0f + (1.0f/3.0f),15);

  if (xyz.y<0.0f && ay>=ax && ay>=az) // -Y, Face 3, bottom
    return _tex2DVecN(t,(xyz.x/ay+1.0f)/8.0f + 0.25f,(xyz.z/ay+1.0f)/6.0f,15);

  if (xyz.z<0.0f && az>=ax && az>=ay) // -Z, Face 5, back
    return _tex2DVecN(t,(-xyz.x/az+1.0f)/8.0f + 0.75f,(xyz.y/az+1.0f)/6.0f + (1.0f/3.0f),15);

  return to_float4(1.0f,0.0f,0.0f,1.0f); // error
}


]]
-- /*



-- // ------------------------------------------------------------------------
-- DCTL kernel implementation
-- // ------------------------------------------------------------------------

-- */
ShaderKernelCode =
[[

// ----------------------------------------------------------------------------------
// - Image                                                                          -
// ----------------------------------------------------------------------------------
// Connect Image 'Texture: Rock Tiles' to iChannel0
// Connect Image 'Cubemap: St Peters Basilica_0' to iChannel1

#define texture(ch,uv) _tex2DVecN(ch, (uv).x, (uv).y, 15)

// Copyright (c) Timo Saarinen 2021
// You can use this Work in a Good and Cool Spirit.
//
// KISS Path Tracing 001: Spheres and a Plane
//------------------------------------------------------------------------
// There are two main approaches to rendering, rasterization
// and ray tracing (RT). Like the name says, ray tracing is
// just tracing through 3D space (usually), simple!
//
// Path Tracing is a type of ray tracing,
// and at its heart.. very simple!
//
// From wikipedia [https://en.wikipedia.org/wiki/Path_tracing]:
//   Path tracing is a computer graphics Monte Carlo method of rendering images of three-dimensional scenes such that the global illumination is faithful to reality. Fundamentally, the algorithm is integrating over all the illuminance arriving to a single point on the surface of an object. This illuminance is then reduced by a surface reflectance function (BRDF) to determine how much of it will go towards the viewpoint camera. This integration procedure is repeated for every pixel in the output image. When combined with physically accurate models of surfaces, accurate models of real light sources (light bulbs), and optically correct cameras, path tracing can produce still images that are indistinguishable from photographs.
//   Path tracing naturally simulates many effects that have to be specifically added to other methods (conventional ray tracing or scanline rendering), such as soft shadows, depth of field, motion blur, caustics, ambient occlusion, and indirect lighting. Implementation of a renderer including these effects is correspondingly simpler. An extended version of the algorithm is realized by volumetric path tracing, which considers the light scattering of a scene.
//   Due to its accuracy, unbiased nature, and algorithmic simplicity, path tracing is used to generate reference images when testing the quality of other rendering algorithms. However, the path tracing algorithm is relatively inefficient: a very large number of rays must be traced to get high-quality images free of noise artifacts. Several variants have been introduced which are more efficient than the original algorithm for many scenes, including bidirectional path tracing, volumetric path tracing, and Metropolis light transport.
//
// Spheres and planes are the common first examples of ray tracing,
// with simple intersection code, so let's start with them..
//
// Unoptimized for clarity! Also disclaimer: WIP
#define PI  3.141592f        // close enough
#define EPSILON  0.0001f
#define NOHIT  999999999.0f  // keep positive intersection miss, so can easily _fminf() the closest one

#define ID_NONE        0
#define ID_SPHERE01    1
#define ID_SPHERE02    2
#define ID_SPHERE03    3
#define ID_PLANE       4



// Animate sphere positions
__DEVICE__ float3 sphere_center(int n, float sphere_radius, float iTime) {
    float3 p;
    // rotate around the world center, sphere bottom touching the floor
    p.x = _sinf(iTime + (float)(n)*2.0f*PI/3.0f)*(sphere_radius + _fabs(_sinf(iTime))*sphere_radius);
    p.z = _cosf(iTime + (float)(n)*2.0f*PI/3.0f)*(sphere_radius + _fabs(_sinf(iTime))*sphere_radius);
    p.y = sphere_radius;

    // and.. bounce!
    float ifreq = 2.0f*PI;
    float dur = 0.75f;
    float t = (mod_f(iTime, ifreq) - (ifreq-dur)) / dur; // [0,1] if bouncing
    if(t >= 0.0f) p.y += _fabs(_sinf(t*PI)*sphere_radius*2.0f); // jump!
    return p;
}

// Let's use full 4x4 transformation matrices here.
//
// One way is think them as 4 x vec4:
//      to_float4(swi3(xaxis,x,y,z), translation.x)
//      to_float4(swi3(yaxis,x,y,z), translation.y)
//      to_float4(swi3(zaxis,x,y,z), translation.z)
//      to_float4(0, 0, 0,   1.0f)
//
// TODO: open more?
// TODO: looking "top-down" 4D vector .w component is
//     0.0f for directions (X/Y/Z) and
//     1.0f for locations (T)

// Look from origin "o" to target point "p" with up vector "up"
__DEVICE__ mat4 lookat(in float3 o, in float3 p, in float3 up)
{
    float3 delta = p - o;
    float3 z = normalize(delta); // the direction to look at (Z-axis)
    float3 x = normalize(cross(z, up)); // -> to-right direction (X-axis)
    float3 y = normalize(cross(x, z)); // -> to-up direction (Y-axis)

    // let's do it "unwrapped" for now..
    mat4 translation = to_mat4_f4(
        to_float4(1, 0, 0, -o.x),
        to_float4(0, 1, 0, -o.y),
        to_float4(0, 0, 1, -o.z),
        to_float4(0, 0, 0, 1));

    mat4 rotation = to_mat4_f4(
        to_float4_aw(swi3(x,x,y,z), 0),
        to_float4_aw(swi3(y,x,y,z), 0),
        to_float4_aw(swi3(z,x,y,z), 0),
        to_float4(0,0,0, 1));

    return mul_mat4_mat4(rotation , translation);
}

// Transform a 3D direction vector by a 4x4 matrix
__DEVICE__ float3 transform_dir(float3 dir, mat4 m) {
    return swi3((mul_mat4_f4(m , to_float4_aw(dir, 0.0f))),x,y,z);
}

// Find an intersection between ray ro+t*rd, where t=[0, <NOHIT]
// and a sphere located at "p" with radius "r".
//
// If hits, returns "t", otherwise NOHIT.
__DEVICE__ float isect_ray_sphere(in float3 ro, in float3 rd, in float3 p, in float r) {
    float3 oc = ro - p;
    float b = dot(oc, rd);
    float c = dot(oc, oc) - r*r;
    float t = b*b - c;
    float t2 = (t > 0.0f) ? -b - _sqrtf(t) : NOHIT;
    return (t2 > 0.0f) ? t2 : NOHIT;
}

// Find an intersection between ray ro+t*rd, where t=[0, <NOHIT]
// and a plane going through point "p" with normal "n".
//
// If hits, returns t >= 0.0f, otherwise NOHIT.
__DEVICE__ float isect_ray_plane(in float3 ro, in float3 rd, in float3 p, in float3 n) {

    float denom = dot(rd, -n);
    return (denom > 0.0f) ? -dot(p - ro, n) / denom : NOHIT;
}

// Sample background from cubemap
__DEVICE__ float3 background(float3 dir, __TEXTURE2D__ iChannel1) {
    return swi3(decube_f3(iChannel1, dir),x,y,z);
}

// Returns "t" if hits something, otherwise NOHIT
__DEVICE__ float hit(in float3 ro, in float3 rd, out float3 *hitp, out float3 *hitn, out int *id, float sphere_radius, float3 planen, float iTime) {
    // scene: 3 spheres + plane
    float3 scenter1 = sphere_center(0,sphere_radius,iTime);
    float3 scenter2 = sphere_center(1,sphere_radius,iTime);
    float3 scenter3 = sphere_center(2,sphere_radius,iTime);

    float sphe1_t = isect_ray_sphere(ro, rd, scenter1, sphere_radius);
    float sphe2_t = isect_ray_sphere(ro, rd, scenter2, sphere_radius);
    float sphe3_t = isect_ray_sphere(ro, rd, scenter3, sphere_radius);
    float plane_t = isect_ray_plane(ro, rd, to_float3(0,0,0), planen);

    float t = _fminf(sphe1_t, _fminf(sphe2_t, _fminf(sphe3_t, plane_t))); // closest hit or NOHIT
    *hitp = ro + t*rd; // world hit point

    // object id + world hit normal
    if( t == NOHIT   ) { *id = ID_NONE;     *hitn = -rd; } else
    if( t == sphe1_t ) { *id = ID_SPHERE01; *hitn = normalize(*hitp - scenter1); } else
    if( t == sphe2_t ) { *id = ID_SPHERE02; *hitn = normalize(*hitp - scenter2); } else
    if( t == sphe3_t ) { *id = ID_SPHERE03; *hitn = normalize(*hitp - scenter3); } else
    if( t == plane_t ) { *id = ID_PLANE;    *hitn = planen; }

    // add some epsilon to position to compensate floating point inaccuracies
    *hitp += EPSILON* *hitn;
    return t;
}

// path tracing
__DEVICE__ float3 trace(in float3 ro, in float3 rd, __TEXTURE2D__ iChannel0, __TEXTURE2D__ iChannel1, float sphere_radius, float3 planen, float plane_halfsize, float3 sun_dir, float iTime, float ratio) {
    const int maxdepth = 3;
    for(int depth=0; depth < maxdepth; ++depth) {
        int id;
        float3 hitp; // world position of hit point
        float3 hitn; // world normal of hit point
        float t = hit(ro, rd, &hitp, &hitn, &id, sphere_radius,planen,iTime); // sets "hitp", "hitn", "id"

        switch(id) {
            case ID_SPHERE01:
            case ID_SPHERE02:
            case ID_SPHERE03: {
                // hits a sphere - 100% reflective, so continue path to reflection direction
                float3 reflection = normalize(reflect(rd, hitn)); // reflect the ray around sphere normal
                ro = hitp;
                rd = reflection;
                break;
            }
            default:
                // make up rectangular floor plane area
                if( id == ID_PLANE && _fabs(hitp.x) < plane_halfsize && _fabs(hitp.z) < plane_halfsize ) {
                    float3 unused_p; float3 unused_n; int unused_id;
                    float shadowhitt = hit(hitp, sun_dir, &unused_p, &unused_n, &unused_id, sphere_radius,planen,iTime); // shadow from sun, 1.0f if unblocked
                    float3 shadowmul = _mix(to_float3_s(0.5f), to_float3_s(1), _fminf(1.0f, 0.25f*shadowhitt)); // fake gradient by shadower distance
                    float2 tuv = to_float2( hitp.x*ratio, hitp.z);
                    //float3 tex = swi3(texture(iChannel0, swi2(hitp,x,z)),x,y,z); // sample 2D floor texture
                    float3 tex = swi3(texture(iChannel0, tuv),x,y,z); // sample 2D floor texture
                    return shadowmul * tex;
                } else {
                    // misses scene objects -> background, terminate path
                    return background(rd,iChannel1);
                }
        }
    }
    return to_float3_s(0.0f);
}

__KERNEL__ void KissTracingFuse(__CONSTANTREF__ Params*  params,  __TEXTURE2D__ iChannel0,  __TEXTURE2D__ iChannel1, __TEXTURE2D_WRITE__ destinationTexture)
{
   DEFINE_KERNEL_ITERATORS_XY(fusion_x, fusion_y);

   if (fusion_x >= params->width || fusion_y >= params->height)
     return;

  float2 iResolution = to_float2(params->iResolution[0], params->iResolution[1]);
  float  iTime       = params->iTime;
  float4 iMouse      = to_float4(params->iMouse[0],params->iMouse[1],params->iMouse[2],params->iMouse[3]);
  float4 fragColor   = to_float4_s(0.0f);
  float2 fragCoord   = to_float2(fusion_x,fusion_y);



  // --------



    const float3 sun_dir = normalize(to_float3(1,1,1));
    const float camera_distance = 1.5f;
    const float sphere_radius = 0.5f;
    const float3 planen = to_float3(0,1,0);
    const float plane_halfsize = 3.0f; // floor "rectangle"
    float ratio = iResolution.y/iResolution.x;

    float2 rotation = swi2(iMouse,x,y) / iResolution; rotation.y = 1.0f - rotation.y; // Mouse [0,1] + tweak
    float2 p = (2.0f*fragCoord - iResolution) / iResolution.y; // Pixel coordinates y=[-1,1], x=[-1*aspect,1*aspect] where aspect=width/height

    float3 ro = to_float3(_sinf(-rotation.x*PI)*camera_distance, 1.1f + _cosf(-rotation.y*PI)*1.0f, _cosf(-rotation.x*PI)*camera_distance); // Mouse rotation around the sphere -> ray origin (camera position)
    mat4 m = lookat(ro, to_float3(0,sphere_radius,0), to_float3(0,1,0)); // Camera->World transformation matrix
    float3 ldir = normalize(to_float3_aw(p, 1.0f)); // Local ray direction (Camera Space)
    float3 rd = transform_dir(ldir, m); // -> World Space

    float3 c = trace(ro, rd,iChannel0,iChannel1, sphere_radius, planen, plane_halfsize, sun_dir,iTime, ratio);

    fragColor = to_float4_aw(c, 1.0f);


  _tex2DVec4Write(destinationTexture, fusion_x, fusion_y, fragColor);
}
]]
-- /*



-- // ------------------------------------------------------------------------
-- // Create
-- // ------------------------------------------------------------------------

function Create()

  ShaderFuse.begin_create()

  ----- In/Out

  InChannel0 = self:AddInput( "iChannel0",  "iChannel0",  { LINKID_DataType = "Image", LINK_Main = 1, INP_Required = false  })
  InChannel1 = self:AddInput( "iChannel1",  "iChannel1",  { LINKID_DataType = "Image", LINK_Main = 2, INP_Required = false  })

  OutImage = self:AddOutput("Output", "Output", {
    LINKID_DataType = "Image",
    LINK_Main       = 1,
  })

  ----- Inspector Panel Controls

  
  -- Speed Slider
  
  InFrequency = self:AddInput("Speedup", "speed", {
    LINKID_DataType    = "Number",
    INPID_InputControl = "SliderControl",
    INP_Default        = 1.0,
    INP_MinScale 	     = 0.0,
    INP_MaxScale 	     = 5.0,
    SLCS_LowName       = "stop",
    SLCS_HighName      = "5x",
  })
  
  -- iMouse Controls
  
  InMouseXY = self:AddInput("iMouse.xy", "iMouseXY", {
    LINKID_DataType = "Point",
    INPID_InputControl = "OffsetControl",
    INP_DoNotifyChanged  = false,
    --INP_Passive = true,
    INPID_PreviewControl = "CrosshairControl",
  })
  
  InMouseZW = self:AddInput("iMouse.zw", "iMouseZW", {
    LINKID_DataType = "Point",
    INPID_InputControl = "OffsetControl",
    INP_DoNotifyChanged  = false,
    --INP_Passive = true,
    INPID_PreviewControl = "CrosshairControl",
    INP_Disabled = true,
  })
  
  InMouseDrag = self:AddInput("Mouse Button Pressed", "iMouseClick", {
    LINKID_DataType = "Number",
    INPID_InputControl = "CheckboxControl",
    INP_DoNotifyChanged  = false,
    INP_Passive = true,
    INP_MinScale = 0,
    INP_MaxScale = 1,
    INP_Default = 0,
  })


  ShaderFuse.end_create()

end



-- // ------------------------------------------------------------------------
-- // Process
-- // ------------------------------------------------------------------------

function Process(req)

  local imgattrs = {
    IMG_Document = self.Comp,
    { IMG_Channel = "Red", },
    { IMG_Channel = "Green", },
    { IMG_Channel = "Blue", },
    { IMG_Channel = "Alpha", },
    IMG_Width  = Width,
    IMG_Height = Height,
    IMG_XScale = XAspect,
    IMG_YScale = YAspect,
    IMAT_OriginalWidth  = realwidth, -- nil !?!
    IMAT_OriginalHeight = realheight, -- nil !?!
    IMG_Quality = not req:IsQuick(),
    IMG_MotionBlurQuality = not req:IsNoMotionBlur(),
    IMG_DeferAlloc = true,
    IMG_ProxyScale = ( (not req:IsStampOnly()) and 1 or nil),
    IMG_Depth = ( (SourceDepth~=0) and SourceDepth or nil   )
  }

  local dst   = Image(imgattrs)
  local black = Pixel({R=0,G=0,B=0,A=0})
  dst:Fill(black)

  if req:IsPreCalc() then
    local out = Image({IMG_Like = dst, IMG_NoData = true})
    OutImage:Set(req, out)
    return
  end

  local node = DVIPComputeNode(req,
    "KissTracingFuse", ShaderCompatibilityCode..ShaderKernelCode,
    "Params", ShaderParameters
  )

  -- Extern texture or create a new one

  iChannel0 = InChannel0:GetValue(req)

  if iChannel0==nil then
    iChannel0 = Image(imgattrs)
    iChannel0:Fill(black)
  end

  iChannel1 = InChannel1:GetValue(req)

  if iChannel1==nil then
    iChannel1 = Image(imgattrs)
    iChannel1:Fill(black)
  end

  -- DCTL parameters

  local framerate = self.Comp:GetPrefs("Comp.FrameFormat.Rate")

  local params = {}

  params = node:GetParamBlock(ShaderParameters)

  params.iResolution[0] = dst.Width
  params.iResolution[1] = dst.Height
  params.iTime = (req.Time / framerate) * InFrequency:GetValue(req).Value
  
  -- iMouse
  
  local mouse_xy  = InMouseXY:GetValue(req)
  local mouse_zw  = InMouseZW:GetValue(req)
  
  params.iMouse[0] = mouse_xy.X
  params.iMouse[1] = mouse_xy.Y
  params.iMouse[2] = mouse_zw.X
  params.iMouse[3] = mouse_zw.Y
  
  if InMouseDrag:GetValue(req).Value ~= 0 then
    if params.iMouse[2]==-1 and params.iMouse[3]==-1 then
      params.iMouse[2]=params.iMouse[0]
      params.iMouse[3]=params.iMouse[1]
    end
  else
    params.iMouse[2] = -1
    params.iMouse[3] = -1
  end
  
  if mouse_zw.X ~= params.iMouse[2] or mouse_zw.Y ~= params.iMouse[3] then
    InMouseZW:SetAttrs({INP_Disabled=false})
    InMouseZW:SetSource(Point(params.iMouse[2],params.iMouse[3]),0,0)
    InMouseZW:SetAttrs({INP_Disabled=true})
  end
  
  params.iMouse[0] = params.iMouse[0] * Width
  params.iMouse[1] = params.iMouse[1] * Height
  if params.iMouse[2] == -1 and params.iMouse[3] == -1 then
    params.iMouse[2] = 0
    params.iMouse[3] = 0
  else
    params.iMouse[2] = params.iMouse[2] * Width
    params.iMouse[3] = params.iMouse[3] * Height
  end

  -- Resolution

  params.width  = dst.Width
  params.height = dst.Height

  -- Per channel time and resolution


  -- Set parameters and add I/O

  node:SetParamBlock(params)
  node:AddSampler("RowSampler", TEX_FILTER_MODE_LINEAR,TEX_ADDRESS_MODE_MIRROR, TEX_NORMALIZED_COORDS_TRUE)
  node:AddInput("iChannel0",iChannel0) -- TODO: add a better channel name
  node:AddInput("iChannel1",iChannel1) -- TODO: add a better channel name
  node:AddOutput("dst", dst)

  local ok = node:RunSession(req)

	if (not ok) then
		dst = nil
    dump(node:GetErrorLog())
	end

  OutImage:Set(req,dst)
end



-- // ------------------------------------------------------------------------
-- // Callback
-- // ------------------------------------------------------------------------

-- function NotifyChanged(inp, param, time)
-- 	if (param ~= nil) then
-- 		if (param.Value == 1) then
-- 			if (inp == ...) then
--         ...
-- 			end
-- 		end
-- 	end
-- end


-- */


